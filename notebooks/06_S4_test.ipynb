{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c6041c64",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../src\")\n",
    "\n",
    "from models.s4d import S4DModel, S4DConfig, S4DModelForHourlySeries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df = pd.read_csv(\"../data/merged_data.csv\", parse_dates=[\"datetime\"])\n",
    "df = df.sort_values(\"datetime\")\n",
    "df = df.dropna()\n",
    "\n",
    "features = [\n",
    "    \"temperature_2m\", \"wind_speed_180m\", \"wind_speed_120m\", \"direct_radiation\",\n",
    "    \"quantity_biomass\", \"quantity_fossil_gas\", \"quantity_fossil_hard_coal\",\n",
    "    \"quantity_hydro_run_of_river\", \"quantity_nuclear\", \"quantity_solar\",\n",
    "    \"quantity_waste\", \"quantity_wind_offshore\", \"quantity_wind_onshore\",\n",
    "    \"quantity_other\", \"quantity_MW\"\n",
    "]\n",
    "target = \"price_EUR_MWh\"\n",
    "\n",
    "scaler_x = StandardScaler()\n",
    "scaler_y = StandardScaler()\n",
    "\n",
    "X = scaler_x.fit_transform(df[features])\n",
    "y = scaler_y.fit_transform(df[[target]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9172e736",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TimeSeriesDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Custom Dataset for time series data with fixed sequence length.\n",
    "    \"\"\"\n",
    "    def __init__(self, X, y, seq_len):\n",
    "        self.X = torch.tensor(X, dtype=torch.float32)\n",
    "        self.y = torch.tensor(y, dtype=torch.float32)\n",
    "        self.seq_len = seq_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X) - self.seq_len\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        x = self.X[idx : idx + sequence_length]          # input sequence of length 24\n",
    "        t = self.y[idx + sequence_length : idx + 2*sequence_length]  # target: next 24 steps\n",
    "        return x, t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3ad5b0c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the dataset into training and validation sets\n",
    "# Assuming the data is hourly and we want to validate on the last 30 days\n",
    "sequence_length = 24 # 24 hours = 1 day\n",
    "val_days = 30\n",
    "val_size = val_days * 24\n",
    "\n",
    "train_X = X[:-val_size]\n",
    "train_y = y[:-val_size]\n",
    "val_X = X[-val_size - sequence_length:]\n",
    "val_y = y[-val_size - sequence_length:]\n",
    "\n",
    "train_dataset = TimeSeriesDataset(train_X, train_y, sequence_length)\n",
    "val_dataset = TimeSeriesDataset(val_X, val_y, sequence_length)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dc0cd5d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preds.shape = torch.Size([32, 24])\n",
      "t.shape = torch.Size([32, 1])\n",
      "t_squeezed.shape = torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Uni\\Zurich\\Semester 1\\Advanced Machine Learning\\project\\aml2025-group-15-main\\aml2025-group-15\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\loss.py:608: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 24])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (24) must match the size of tensor b (32) at non-singleton dimension 1",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 30\u001b[39m\n\u001b[32m     28\u001b[39m t_squeezed = t.squeeze(-\u001b[32m1\u001b[39m)\n\u001b[32m     29\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mt_squeezed.shape = \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mt_squeezed.shape\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m30\u001b[39m loss = \u001b[43mcriterion\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpreds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m.\u001b[49m\u001b[43msqueeze\u001b[49m\u001b[43m(\u001b[49m\u001b[43m-\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     31\u001b[39m loss.backward()\n\u001b[32m     32\u001b[39m optimizer.step()\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Uni\\Zurich\\Semester 1\\Advanced Machine Learning\\project\\aml2025-group-15-main\\aml2025-group-15\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1734\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1735\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1736\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Uni\\Zurich\\Semester 1\\Advanced Machine Learning\\project\\aml2025-group-15-main\\aml2025-group-15\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1742\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1743\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1744\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1745\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1746\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1747\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1749\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1750\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Uni\\Zurich\\Semester 1\\Advanced Machine Learning\\project\\aml2025-group-15-main\\aml2025-group-15\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\loss.py:608\u001b[39m, in \u001b[36mMSELoss.forward\u001b[39m\u001b[34m(self, input, target)\u001b[39m\n\u001b[32m    607\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor, target: Tensor) -> Tensor:\n\u001b[32m--> \u001b[39m\u001b[32m608\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmse_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreduction\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mreduction\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Uni\\Zurich\\Semester 1\\Advanced Machine Learning\\project\\aml2025-group-15-main\\aml2025-group-15\\.venv\\Lib\\site-packages\\torch\\nn\\functional.py:3791\u001b[39m, in \u001b[36mmse_loss\u001b[39m\u001b[34m(input, target, size_average, reduce, reduction)\u001b[39m\n\u001b[32m   3788\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m size_average \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m reduce \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   3789\u001b[39m     reduction = _Reduction.legacy_get_string(size_average, reduce)\n\u001b[32m-> \u001b[39m\u001b[32m3791\u001b[39m expanded_input, expanded_target = \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbroadcast_tensors\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3792\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m torch._C._nn.mse_loss(\n\u001b[32m   3793\u001b[39m     expanded_input, expanded_target, _Reduction.get_enum(reduction)\n\u001b[32m   3794\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Uni\\Zurich\\Semester 1\\Advanced Machine Learning\\project\\aml2025-group-15-main\\aml2025-group-15\\.venv\\Lib\\site-packages\\torch\\functional.py:76\u001b[39m, in \u001b[36mbroadcast_tensors\u001b[39m\u001b[34m(*tensors)\u001b[39m\n\u001b[32m     74\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function(tensors):\n\u001b[32m     75\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(broadcast_tensors, tensors, *tensors)\n\u001b[32m---> \u001b[39m\u001b[32m76\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_VF\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbroadcast_tensors\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mRuntimeError\u001b[39m: The size of tensor a (24) must match the size of tensor b (32) at non-singleton dimension 1"
     ]
    }
   ],
   "source": [
    "# Model Config\n",
    "\n",
    "config = S4DConfig(    \n",
    "    state_size   = 64,\n",
    "    hidden_size  = 32,\n",
    "    num_layers   = 1,\n",
    "    dropout      = 0.1,\n",
    ")\n",
    "\n",
    "# Model, optimizer, and loss function\n",
    "model = S4DModelForHourlySeries(config) #.cuda()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "criterion = nn.MSELoss() #.to(\"cuda\")\n",
    "\n",
    "# Training the model\n",
    "n_epochs = 30\n",
    "model.train()\n",
    "for epoch in range(n_epochs):\n",
    "    epoch_loss = 0\n",
    "    for x, t in train_loader:\n",
    "        # x, t = x.cuda(), t.cuda()\n",
    "        optimizer.zero_grad()\n",
    "        preds = model(x, mode=\"convolutional\")\n",
    "        print(f\"preds.shape = {preds.shape}\")  # should be (batch, 24)\n",
    "        print(f\"t.shape = {t.shape}\")          # should be (batch, 24) or (batch, 24, 1)\n",
    "\n",
    "        # If t has an extra last dim, squeeze it\n",
    "        t_squeezed = t.squeeze(-1)\n",
    "        print(f\"t_squeezed.shape = {t_squeezed.shape}\")\n",
    "        loss = criterion(preds, t.squeeze(-1))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "    # Validation\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for x, t in val_loader:\n",
    "            # x, t = x.cuda(), t.cuda()\n",
    "            preds = model(x)\n",
    "            loss = criterion(preds, t.squeeze(-1))\n",
    "            val_loss += loss.item()\n",
    "    model.train()\n",
    "\n",
    "    print(f\"Epoch {epoch+1}, Train Loss: {epoch_loss/len(train_loader):.4f}, Val Loss: {val_loss/len(val_loader):.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
